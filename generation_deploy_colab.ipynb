{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "083ccc58410249d5bdd234b1aa38707c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e7b5d2c79424f158ac6151a1584d551",
              "IPY_MODEL_8e2f964e6215462da911eef01977a34e",
              "IPY_MODEL_b3390df9e0c64a84b0e1a57f6ce5f229"
            ],
            "layout": "IPY_MODEL_4e75176dd59b40c6acc2cc1f8c84c797"
          }
        },
        "0e7b5d2c79424f158ac6151a1584d551": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05a6d52d5d4b4898a3a2606638a63329",
            "placeholder": "​",
            "style": "IPY_MODEL_09f9de74226947449fdd4224f87fca6f",
            "value": "Downloading: 100%"
          }
        },
        "8e2f964e6215462da911eef01977a34e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d372bbc938bb42d49c7febae065eb36e",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_492ee9e4987f42fe88e019a395e970af",
            "value": 1000
          }
        },
        "b3390df9e0c64a84b0e1a57f6ce5f229": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_265be4631e3c4c1b910caa11687116ef",
            "placeholder": "​",
            "style": "IPY_MODEL_85cf2dc5aa6646e9b3c5d34b9c263767",
            "value": " 1.00k/1.00k [00:00&lt;00:00, 40.7kB/s]"
          }
        },
        "4e75176dd59b40c6acc2cc1f8c84c797": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05a6d52d5d4b4898a3a2606638a63329": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09f9de74226947449fdd4224f87fca6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d372bbc938bb42d49c7febae065eb36e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "492ee9e4987f42fe88e019a395e970af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "265be4631e3c4c1b910caa11687116ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85cf2dc5aa6646e9b3c5d34b9c263767": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7547b9a055a42f6b71a608672186d97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c0ca240f443d4aee980067e4a554bd6d",
              "IPY_MODEL_b5680771e4714a8ea9d8ba5be7981aea",
              "IPY_MODEL_749d7c13c426472e83db2f14cbbfca21"
            ],
            "layout": "IPY_MODEL_d1a6616d16f04463a0d1a7b83184989e"
          }
        },
        "c0ca240f443d4aee980067e4a554bd6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_374cbac1d17e4f2ea1e9cb736f32e0f5",
            "placeholder": "​",
            "style": "IPY_MODEL_ac22316a80e8480b83a3ac7a1a7102ca",
            "value": "Downloading: 100%"
          }
        },
        "b5680771e4714a8ea9d8ba5be7981aea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8977203352724ddf924bf419d8c3c6e9",
            "max": 513302779,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c84a52bb581b4a7d8b85a9f6d10afd2d",
            "value": 513302779
          }
        },
        "749d7c13c426472e83db2f14cbbfca21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_674859c8390c4443bb2c9efcbc6737b7",
            "placeholder": "​",
            "style": "IPY_MODEL_f2ef03a0841d44e1a2051e4f635f2d15",
            "value": " 513M/513M [00:10&lt;00:00, 56.3MB/s]"
          }
        },
        "d1a6616d16f04463a0d1a7b83184989e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "374cbac1d17e4f2ea1e9cb736f32e0f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac22316a80e8480b83a3ac7a1a7102ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8977203352724ddf924bf419d8c3c6e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c84a52bb581b4a7d8b85a9f6d10afd2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "674859c8390c4443bb2c9efcbc6737b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2ef03a0841d44e1a2051e4f635f2d15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e9883a775624fcb8fe39e7fd7b3e66b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e94bc6915e8c443ba9e29569055ab0ce",
              "IPY_MODEL_8ce406bf4fc64d51b3e122cae64fbfac",
              "IPY_MODEL_18717f197eb941e6924b18953a07f8ad"
            ],
            "layout": "IPY_MODEL_17593c767e034ce4a5d9578d5956d94b"
          }
        },
        "e94bc6915e8c443ba9e29569055ab0ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d266b33654b545848162b02a5736a2ae",
            "placeholder": "​",
            "style": "IPY_MODEL_4df1605741024d63998135ba5a2fb527",
            "value": "Downloading: 100%"
          }
        },
        "8ce406bf4fc64d51b3e122cae64fbfac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3b745d60ffe404fbfdb942f279902ee",
            "max": 2825034,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5cbc0245f71c47bfaf01fb8c221ff49b",
            "value": 2825034
          }
        },
        "18717f197eb941e6924b18953a07f8ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab791e22feab4f5a9f9daa765760928e",
            "placeholder": "​",
            "style": "IPY_MODEL_fefd1a6f75b24f5da8b61a1b0010ad54",
            "value": " 2.83M/2.83M [00:00&lt;00:00, 15.4MB/s]"
          }
        },
        "17593c767e034ce4a5d9578d5956d94b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d266b33654b545848162b02a5736a2ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4df1605741024d63998135ba5a2fb527": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3b745d60ffe404fbfdb942f279902ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cbc0245f71c47bfaf01fb8c221ff49b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab791e22feab4f5a9f9daa765760928e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fefd1a6f75b24f5da8b61a1b0010ad54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hkdan502/NLP_Basics/blob/main/generation_deploy_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oaGGhdmYKqt"
      },
      "source": [
        "# 패키지 설치\n",
        "pip 명령어로 의존성 있는 패키지를 설치합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8TJkXkpDnSq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd023a54-817b-469a-86b2-fd970cc86ded"
      },
      "source": [
        "!pip install ratsnlp"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ratsnlp\n",
            "  Downloading ratsnlp-1.0.52-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 KB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flask-cors>=3.0.10\n",
            "  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n",
            "Collecting pytorch-lightning==1.6.1\n",
            "  Downloading pytorch_lightning-1.6.1-py3-none-any.whl (582 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m582.5/582.5 KB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Korpora>=0.2.0\n",
            "  Downloading Korpora-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 KB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flask>=1.1.4 in /usr/local/lib/python3.8/dist-packages (from ratsnlp) (1.1.4)\n",
            "Collecting flask-ngrok>=0.0.25\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Collecting transformers==4.10.0\n",
            "  Downloading transformers-4.10.0-py3-none-any.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.1->ratsnlp) (23.0)\n",
            "Requirement already satisfied: torch>=1.8.* in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.1->ratsnlp) (1.13.1+cu116)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.1->ratsnlp) (1.21.6)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.1->ratsnlp) (6.0)\n",
            "Collecting torchmetrics>=0.4.1\n",
            "  Downloading torchmetrics-0.11.1-py3-none-any.whl (517 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.2/517.2 KB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.1->ratsnlp) (4.5.0)\n",
            "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.1->ratsnlp) (2023.1.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.1->ratsnlp) (4.64.1)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.1->ratsnlp) (2.11.2)\n",
            "Collecting pyDeprecate<0.4.0,>=0.3.1\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.10.0->ratsnlp) (2022.6.2)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.10.0->ratsnlp) (3.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.10.0->ratsnlp) (2.25.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.0.12\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.8/dist-packages (from flask>=1.1.4->ratsnlp) (2.11.3)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.8/dist-packages (from flask>=1.1.4->ratsnlp) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.8/dist-packages (from flask>=1.1.4->ratsnlp) (1.1.0)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.8/dist-packages (from flask>=1.1.4->ratsnlp) (7.1.2)\n",
            "Requirement already satisfied: Six in /usr/local/lib/python3.8/dist-packages (from flask-cors>=3.0.10->ratsnlp) (1.15.0)\n",
            "Collecting dataclasses>=0.6\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: xlrd>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from Korpora>=0.2.0->ratsnlp) (1.2.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.1->ratsnlp) (3.8.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from Jinja2<3.0,>=2.10.1->flask>=1.1.4->ratsnlp) (2.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.10.0->ratsnlp) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.10.0->ratsnlp) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.10.0->ratsnlp) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.10.0->ratsnlp) (2022.12.7)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (1.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (0.38.4)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (2.16.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (1.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (0.4.6)\n",
            "Requirement already satisfied: protobuf<4,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (3.19.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (1.51.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (57.4.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==4.10.0->ratsnlp) (1.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.1->ratsnlp) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.1->ratsnlp) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.1->ratsnlp) (22.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.1->ratsnlp) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.1->ratsnlp) (6.0.4)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.1->ratsnlp) (3.0.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.1->ratsnlp) (1.8.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (6.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (3.13.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (3.2.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=174afd2a79bff6aa58cc601a8b5ee3401917829a90d4aaec65c294d30b703e01\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, dataclasses, sacremoses, pyDeprecate, torchmetrics, Korpora, huggingface-hub, transformers, flask-ngrok, flask-cors, pytorch-lightning, ratsnlp\n",
            "Successfully installed Korpora-0.2.0 dataclasses-0.6 flask-cors-3.0.10 flask-ngrok-0.0.25 huggingface-hub-0.12.1 pyDeprecate-0.3.2 pytorch-lightning-1.6.1 ratsnlp-1.0.52 sacremoses-0.0.53 tokenizers-0.10.3 torchmetrics-0.11.1 transformers-4.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3mThtbxyNyO"
      },
      "source": [
        "# 모델 로딩\n",
        "프리트레인한 GPT2 모델과 토크나이저를 읽어 들입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFV031RZFRgD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "083ccc58410249d5bdd234b1aa38707c",
            "0e7b5d2c79424f158ac6151a1584d551",
            "8e2f964e6215462da911eef01977a34e",
            "b3390df9e0c64a84b0e1a57f6ce5f229",
            "4e75176dd59b40c6acc2cc1f8c84c797",
            "05a6d52d5d4b4898a3a2606638a63329",
            "09f9de74226947449fdd4224f87fca6f",
            "d372bbc938bb42d49c7febae065eb36e",
            "492ee9e4987f42fe88e019a395e970af",
            "265be4631e3c4c1b910caa11687116ef",
            "85cf2dc5aa6646e9b3c5d34b9c263767",
            "e7547b9a055a42f6b71a608672186d97",
            "c0ca240f443d4aee980067e4a554bd6d",
            "b5680771e4714a8ea9d8ba5be7981aea",
            "749d7c13c426472e83db2f14cbbfca21",
            "d1a6616d16f04463a0d1a7b83184989e",
            "374cbac1d17e4f2ea1e9cb736f32e0f5",
            "ac22316a80e8480b83a3ac7a1a7102ca",
            "8977203352724ddf924bf419d8c3c6e9",
            "c84a52bb581b4a7d8b85a9f6d10afd2d",
            "674859c8390c4443bb2c9efcbc6737b7",
            "f2ef03a0841d44e1a2051e4f635f2d15"
          ]
        },
        "outputId": "dfad76ff-bc48-41c9-adef-65b760d2096c"
      },
      "source": [
        "from transformers import GPT2LMHeadModel\n",
        "model = GPT2LMHeadModel.from_pretrained(\n",
        "    \"skt/kogpt2-base-v2\",\n",
        ")\n",
        "model.eval()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "083ccc58410249d5bdd234b1aa38707c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/513M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7547b9a055a42f6b71a608672186d97"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(51200, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=51200, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3amlsjpFd9i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151,
          "referenced_widgets": [
            "8e9883a775624fcb8fe39e7fd7b3e66b",
            "e94bc6915e8c443ba9e29569055ab0ce",
            "8ce406bf4fc64d51b3e122cae64fbfac",
            "18717f197eb941e6924b18953a07f8ad",
            "17593c767e034ce4a5d9578d5956d94b",
            "d266b33654b545848162b02a5736a2ae",
            "4df1605741024d63998135ba5a2fb527",
            "b3b745d60ffe404fbfdb942f279902ee",
            "5cbc0245f71c47bfaf01fb8c221ff49b",
            "ab791e22feab4f5a9f9daa765760928e",
            "fefd1a6f75b24f5da8b61a1b0010ad54"
          ]
        },
        "outputId": "61394aad-e31e-47b4-b0f1-9f6c3a657001"
      },
      "source": [
        "from transformers import PreTrainedTokenizerFast\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(\n",
        "    \"skt/kogpt2-base-v2\",\n",
        "    eos_token=\"</s>\",\n",
        ")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.83M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e9883a775624fcb8fe39e7fd7b3e66b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_b-3ZCPNQ5p"
      },
      "source": [
        "## 프롬프트 준비\n",
        "\n",
        "언어모델에 넣을 프롬프트를 준비합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhGrFki_M6CT"
      },
      "source": [
        "input_ids = tokenizer.encode(\"안녕하세요\", return_tensors=\"pt\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0yIwXhDNl7i"
      },
      "source": [
        "## Greedy Search\n",
        "\n",
        "\n",
        "다음 단어 확률 분포에서 최대 확률을 내는 단어들을 리턴합니다. \n",
        "여러 번 수행하더라도 생성 결과가 바뀌지 않습니다 (`do_sample=False`).\n",
        "`max_length`는 생성 최대 길이이며 이보다 길거나, 짧더라도 EOD 토큰 등 스페셜 토큰이 나타나면 생성을 중단합니다. `min_length`는 생성 최소 길이이며 이보다 짧은 구간에서 EOD 등 스페셜 토큰이 등장해 생성이 중단될 경우 해당 토큰이 나올 확률을 0으로 수정하여 문장 생성이 종료되지 않도록 강제합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J94NJQRHM9sA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2a4481e-489c-4c3d-cbc8-b78e3a381f66"
      },
      "source": [
        "import torch\n",
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(\n",
        "        input_ids,\n",
        "        do_sample=False,\n",
        "        min_length=10,\n",
        "        max_length=50,\n",
        "    )\n",
        "    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlpAZmbVQ0FN"
      },
      "source": [
        "## Beam Search \n",
        "\n",
        "Beam Search는 다음 단어 확률 분포에서 `num_beams`만큼의 경우의 수를 남겨가면서 문장을 생성합니다. Beam search는 Greedy search보다 계산량이 많지만 좀 더 확률값이 높은 문장을 생성할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZMWKWTyRLA4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac057ed1-fedc-4f6d-9a3c-c25835b2f2ae"
      },
      "source": [
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(\n",
        "        input_ids,\n",
        "        do_sample=False,\n",
        "        min_length=10,\n",
        "        max_length=50,\n",
        "        num_beams=3,\n",
        "    )\n",
        "    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요?\"\n",
            "\"그렇지 않습니다.\"\n",
            "\"그렇지 않습니다.\"\n",
            "\"그렇지 않습니다.\"\n",
            "\"그렇지 않습니다.\"\n",
            "\"그렇지 않습니다.\"\n",
            "\"그렇지 않습니다.\"\n",
            "\"그\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SJsuYFKREfp"
      },
      "source": [
        "`num_beams=1`로 설정하면 정확히 Greedy search와 동일하게 작동합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAioTRj3SuhA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0bc7e59-ad10-4d4a-ab59-21283c233670"
      },
      "source": [
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(\n",
        "        input_ids,\n",
        "        do_sample=False,\n",
        "        min_length=10,\n",
        "        max_length=50,\n",
        "        num_beams=1,\n",
        "    )\n",
        "    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoVeZTxtQDpU"
      },
      "source": [
        "## 반복 줄이기\n",
        "\n",
        "### 반복되는 n-gram 사이즈를 지정하기\n",
        "\n",
        "위의 예시를 보면 `\"그럼, 그건 뭐예요?\"`이 반복됩니다. 이를 아래와 같이 지정해 반복을 방지합니다. 3개 이상의 토큰이 반복될 경우 해당 3-gram 등장 확률을 0으로 만들어 생성 결과에서 배제합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7-ixOKZQYmb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1efeaf6f-7ffd-4f78-bee1-0ca4dd4dfb8d"
      },
      "source": [
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(\n",
        "        input_ids,\n",
        "        do_sample=False,\n",
        "        min_length=10,\n",
        "        max_length=50,\n",
        "        no_repeat_ngram_size=3,\n",
        "    )\n",
        "    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요?\"\n",
            "\"그럼, 그건 뭐예요?\" 하고 나는 물었다.\n",
            "\"그건 뭐죠?\" 나는 물었다.\n",
            "나는 대답하지 않았다.\n",
            "\"그런데 왜 그걸 물어요? 그건 무슨 뜻이에요?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KMSLJm6QnqW"
      },
      "source": [
        "### repetition penalty\n",
        "\n",
        "repetition penalty로 반복을 통제할 수도 있습니다. 다음과 같이 실행하면 되며 그 범위는 1 이상의 값을 가져야 합니다. 1이라면 아무런 패널티를 적용하지 않는게 됩니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-E8zQaKaI0Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3275e893-74c7-4c1a-b879-7cd39c9d417d"
      },
      "source": [
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(\n",
        "        input_ids,\n",
        "        do_sample=False,\n",
        "        min_length=10,\n",
        "        max_length=50,\n",
        "        repetition_penalty=1.0,\n",
        "    )\n",
        "    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UA4sIZ3l2UGD"
      },
      "source": [
        "`repetition_penalty` 값이 클 수록 패널티가 세게 적용됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYYEgzc_QnLm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "400c72ba-db1c-4652-dd2f-555c45d05b21"
      },
      "source": [
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(\n",
        "        input_ids,\n",
        "        do_sample=False,\n",
        "        min_length=10,\n",
        "        max_length=50,\n",
        "        repetition_penalty=1.1,\n",
        "    )\n",
        "    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\"아니요, 저는요.\"\n",
            "\"그럼, 그건 무슨 말씀이신지요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIAHKtfIZ93g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77edfe8f-5b3d-4437-dbb2-62072e342358"
      },
      "source": [
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(\n",
        "        input_ids,\n",
        "        do_sample=False,\n",
        "        min_length=10,\n",
        "        max_length=50,\n",
        "        repetition_penalty=1.2,\n",
        "    )\n",
        "    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요?\"\n",
            "\"그럼, 그건 뭐예요, 아저씨. 저는 지금 이 순간에도 괜찮아요.\"\n",
            "\"그래서 오늘은 제가 할 수 있는 일이 무엇인지 말해 보겠습니다.\"\n",
            "\"이제\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Qe5hlCgaRAL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db9c4459-a09a-453a-a35c-bd76b8db6ce3"
      },
      "source": [
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(\n",
        "        input_ids,\n",
        "        do_sample=False,\n",
        "        min_length=10,\n",
        "        max_length=50,\n",
        "        repetition_penalty=1.5,\n",
        "    )\n",
        "    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요?\"\n",
            "\"그럼, 그건 뭐예요, 아저씨. 저는 지금 이 순간에도 괜찮아요. 그리고 제가 할 수 있는 일은 아무것도 없어요.\n",
            "이제 그만 돌아가고 싶어요.\n",
            "제가 하는 일이 무엇\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CG-THCtUd8BP"
      },
      "source": [
        "## top-k sampling\n",
        "\n",
        "지금까지는 생성을 반복하더라도 그 결과가 동일한 샘플링 방식을 살펴봤습니다. top-k sampling은 다음 단어를 뽑을 때 확률값 기준 가장 큰 k개 가운데 하나를 선택하는 기법입니다. 확률값이 큰 단어가 다음 단어로 뽑힐 가능성이 높아지지만, k개 안에 있는 단어라면 확률값이 낮더라도 다음 단어로 추출될 수 있습니다. 따라서 top-k sampling은 매 시행 때마다 생성 결과가 달라집니다. k는 1 이상의 값을 지녀야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZykqqkLeoGa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d88dd9d7-24d5-4527-e43b-b885789a904b"
      },
      "source": [
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(\n",
        "        input_ids,\n",
        "        do_sample=True,\n",
        "        min_length=10,\n",
        "        max_length=50,\n",
        "        top_k=50,\n",
        "    )\n",
        "    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요?\"\n",
            "\"난 이제 늙어 죽을 나이니까 아직 젊잖아.\"\n",
            "\"네놈이? 너 때문에 왜 그런 짓을 했어?\"\n",
            "\"어쩌다가 이놈의 짓을 한 건데 너 때문입니까\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65_mnOwW219w"
      },
      "source": [
        "k=1일 경우 Greedy search와 동일합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RGBeGUMeoqx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d897a274-76a1-4699-b3e3-f52b27450baa"
      },
      "source": [
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(\n",
        "        input_ids,\n",
        "        do_sample=True,\n",
        "        min_length=10,\n",
        "        max_length=50,\n",
        "        top_k=1,\n",
        "    )\n",
        "    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnI1PwaSgAN3"
      },
      "source": [
        "## top-k sampling + temperature scaling\n",
        "\n",
        "top-k sampling은 temperature scaling과 동시에 적용할 수 있습니다. 그 값에 따라 다음과 같은 효과가 납니다.\n",
        "\n",
        "(1) t가 0에 가까워질 수록 토큰 분포가 sharp해진다 > 1등 토큰이 뽑힐 확률이 그만큼 높아진다 > do_sample=True이지만 사실상 greedy decoding이 된다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OelobEFugAeV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "404a982e-93e6-43f1-9b96-73542d7c346a"
      },
      "source": [
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(\n",
        "        input_ids,\n",
        "        do_sample=True,\n",
        "        min_length=10,\n",
        "        max_length=50,\n",
        "        top_k=50,\n",
        "        temperature=0.01,\n",
        "    )\n",
        "    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1u2O8Vfc3IET"
      },
      "source": [
        "(2) t=1이라면 모델 출력 분포를 그대로 사용한다 > 하지만 샘플링 방식을 사용하기 때문에 생성할 때마다 다른 문장이 나온다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-wV6jAdiF_D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00e06a93-e761-4795-8bad-4b46e2208395"
      },
      "source": [
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(\n",
        "        input_ids,\n",
        "        do_sample=True,\n",
        "        min_length=10,\n",
        "        max_length=50,\n",
        "        top_k=50,\n",
        "        temperature=1.0,\n",
        "    )\n",
        "    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요!\n",
            "아유 감사합니다.\n",
            "저~~~~~~ 안녕하세요~?\n",
            "저~~~~~~~~~~~~~우~~~~~~~~~~~~~\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qJla1_y3N1y"
      },
      "source": [
        "(3) t를 키울수록 토큰 분포가 uniform해진다 > 사실상 uniform sampling이 된다, 생성 품질이 악화할 가능성이 높아진다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnrgKCxuiMrN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8cdbf81-dc94-454c-aa28-df6db4bccf42"
      },
      "source": [
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(\n",
        "        input_ids,\n",
        "        do_sample=True,\n",
        "        min_length=10,\n",
        "        max_length=50,\n",
        "        top_k=50,\n",
        "        temperature=100000000.0,\n",
        "    )\n",
        "    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요`도 하고,요.\n",
            "제가 잘 들어갈거에구~>:: 진짜 진짜 열심히만 하고\n",
            "일요시간 잘 있어서 잘 왔단다.고양시 홈택배에 오지만 그 집에서 놀기도 해서 저도\n",
            "제가 집\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50bBi6ZRihKw"
      },
      "source": [
        "## top-p sampling\n",
        "\n",
        "top-p sampling은 다음 단어를 뽑을 때 누적 확률값이 p 이하인 단어들 가운데 하나를 선택하는 기법입니다. 확률값이 큰 단어가 다음 단어로 뽑힐 가능성이 높아지지만, 누적 확률값 p 이하에 있는 단어라면 확률값이 낮더라도 다음 단어로 추출될 수 있습니다. 따라서 top-p sampling은 매 시행 때마다 생성 결과가 달라집니다. p는 확률이기 때문에 0~1 사이의 값을 지녀야 합니다. p가 1이라면 어휘 집합에 있는 모든 단어를 대상으로 샘플링하기 때문에 top-p sampling 효과가 사라집니다. p가 1보다 약간 작다면 확률값이 낮은 일부 단어들을 다음 단어 후보에서 제거해 생성 품질을 높입니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjNy7gaXkDGn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e261a49a-980e-453f-d555-e72b291df49e"
      },
      "source": [
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(\n",
        "        input_ids,\n",
        "        do_sample=True,\n",
        "        min_length=10,\n",
        "        max_length=50,\n",
        "        top_p=0.92,\n",
        "    )\n",
        "    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요?\"\n",
            "\"그럼, 아, 아, 그래요, 그건 또 다른 문제야. 아까운 걸 어떻게든 갚아나가고 싶지 않아. 아까운 걸 뭐라고 설명할 필요도 없어.\"\n",
            "\"그\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIws234s4JhR"
      },
      "source": [
        "p가 0에 가까울 경우 Greedy search와 비슷해 집니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCAgYU3RkZ80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59b25a8e-9c1e-455f-bcba-87f02aff6b38"
      },
      "source": [
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(\n",
        "        input_ids,\n",
        "        do_sample=True,\n",
        "        min_length=10,\n",
        "        max_length=50,\n",
        "        top_p=0.01,\n",
        "    )\n",
        "    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRR-vy6klf8y"
      },
      "source": [
        "## 통합 적용\n",
        "\n",
        "저희가 실습에 사용하고 있는 허깅페이스(huggingface) 라이브러리의 구현상 적용 순서는 다음과 같습니다.\n",
        "\n",
        "- _get_logits_processor\n",
        "  - RepetitionPenalty\n",
        "  - NoRepeatNGramLogits\n",
        "  - MinLengthLogits\n",
        "- _get_logits_warper\n",
        "  - TemperatureLogits\n",
        "  - TopKLogits\n",
        "  - TopPLogits\n",
        "\n",
        "유효한 설정들을 종합 적용해 문장을 생성하는 코드는 다음과 같습니다. 샘플링(top-k, top-p)을 적용하기 때문에 시행 때마다 다른 문장이 생성됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLo9mtlUmcAK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26a534fd-6fe7-4d4d-af6b-8180d77bda2c"
      },
      "source": [
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(\n",
        "        input_ids,\n",
        "        do_sample=True,\n",
        "        min_length=10,\n",
        "        max_length=50,\n",
        "        repetition_penalty=1.5,\n",
        "        no_repeat_ngram_size=3,\n",
        "        temperature=0.9,\n",
        "        top_k=50,\n",
        "        top_p=0.92,\n",
        "    )\n",
        "    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요?\"라며 \"제가 한 얘기지만 제발 그런 마음을 가지 마시고 꼭 해보도록 하십시오. 죄송합니다\"라고 말했다.\n",
            "이날 방송에서 최동호 작가는 이날 자신을 향한 비판글을 써 논란을 일으킨 MC\n"
          ]
        }
      ]
    }
  ]
}