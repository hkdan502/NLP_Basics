{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hkdan502/NLP/blob/main/embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oaGGhdmYKqt"
      },
      "source": [
        "# 패키지 설치\n",
        "pip 명령어로 의존성 있는 패키지를 설치합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8TJkXkpDnSq"
      },
      "source": [
        "!pip install ratsnlp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFt_JLYoTKA6"
      },
      "source": [
        "## 토크나이저 초기화\n",
        "\n",
        "BERT(`kcbert-base`) 모델이 쓰는 토크나이저를 선언합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bThW-2OrTHZW"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    \"beomi/kcbert-base\",\n",
        "    do_lower_case=False,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0NCnzpRTdnJ"
      },
      "source": [
        "## 모델 초기화\n",
        "\n",
        "BERT(`kcbert-base`) 모델을 읽어들입니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSVDbnFUTiXx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "227f870c-d35a-455d-9b9c-8432d076cbed"
      },
      "source": [
        "from transformers import BertConfig, BertModel\n",
        "pretrained_model_config = BertConfig.from_pretrained(\n",
        "    \"beomi/kcbert-base\"\n",
        ")\n",
        "model = BertModel.from_pretrained(\n",
        "    \"beomi/kcbert-base\",\n",
        "    config=pretrained_model_config,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at beomi/kcbert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWboOauTTyXp"
      },
      "source": [
        "`pretrained_model_config`의 내용을 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tup5LreLT4vE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08f254e7-4751-42bc-831a-e43e2c275567"
      },
      "source": [
        "pretrained_model_config"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertConfig {\n",
              "  \"_name_or_path\": \"beomi/kcbert-base\",\n",
              "  \"architectures\": [\n",
              "    \"BertForMaskedLM\"\n",
              "  ],\n",
              "  \"attention_probs_dropout_prob\": 0.1,\n",
              "  \"classifier_dropout\": null,\n",
              "  \"directionality\": \"bidi\",\n",
              "  \"gradient_checkpointing\": false,\n",
              "  \"hidden_act\": \"gelu\",\n",
              "  \"hidden_dropout_prob\": 0.1,\n",
              "  \"hidden_size\": 768,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 3072,\n",
              "  \"layer_norm_eps\": 1e-12,\n",
              "  \"max_position_embeddings\": 300,\n",
              "  \"model_type\": \"bert\",\n",
              "  \"num_attention_heads\": 12,\n",
              "  \"num_hidden_layers\": 12,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"pooler_fc_size\": 768,\n",
              "  \"pooler_num_attention_heads\": 12,\n",
              "  \"pooler_num_fc_layers\": 3,\n",
              "  \"pooler_size_per_head\": 128,\n",
              "  \"pooler_type\": \"first_token_transform\",\n",
              "  \"position_embedding_type\": \"absolute\",\n",
              "  \"transformers_version\": \"4.10.0\",\n",
              "  \"type_vocab_size\": 2,\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 30000\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y2JYqRGUFll"
      },
      "source": [
        "## 모델 입력값 만들기\n",
        "\n",
        "문장 2개를 모델 입력값으로 만들어보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Rk2Ga65USFb"
      },
      "source": [
        "sentences = [\"안녕하세요\", \"하이!\"]\n",
        "features = tokenizer(\n",
        "    sentences,\n",
        "    max_length=10,\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLq1JRVJUb7U"
      },
      "source": [
        "`features`의 내용을 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZl8OKdsVIQg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74561754-4692-46fe-ee84-c33dbf606f62"
      },
      "source": [
        "features.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzkJ31vQVbjl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7c19110-47e4-4a6b-88cf-42f582b9f5ec"
      },
      "source": [
        "features['input_ids']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2, 19017, 8482, 3, 0, 0, 0, 0, 0, 0], [2, 15830, 5, 3, 0, 0, 0, 0, 0, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lc_71OjafQgS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87bdcbe9-3f8b-41aa-ddb3-ded23b63230d"
      },
      "source": [
        "features['attention_mask']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 1, 1, 1, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 0, 0, 0, 0, 0, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fdv1TGOHfQpm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96262a62-3d37-4e00-f17d-ec5e7b5cec37"
      },
      "source": [
        "features['token_type_ids']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wR-3V6zIVsPp"
      },
      "source": [
        "## BERT 임베딩 추출\n",
        "\n",
        "위에서 만든 `features`를 파이토치 텐서(tensor)로 변환합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdvUPuJoV3w3"
      },
      "source": [
        "import torch\n",
        "features = {k: torch.tensor(v) for k, v in features.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0S2EbdkWIdq"
      },
      "source": [
        "BERT 모델에 `features`를 입력해 계산합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOWkywHaWOL6"
      },
      "source": [
        "outputs = model(**features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fog_9z0SqHog"
      },
      "source": [
        "BERT 마지막 레이어의 단어 수준 벡터들을 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wRQNlJMqMjh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c54d282-e62e-479f-fabe-e28b33a2819f"
      },
      "source": [
        "outputs.last_hidden_state"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.6969, -0.8248,  1.7512,  ..., -0.3732,  0.7399,  1.1907],\n",
              "         [-1.4803, -0.4398,  0.9444,  ..., -0.7405, -0.0211,  1.3064],\n",
              "         [-1.4299, -0.5033, -0.2069,  ...,  0.1285, -0.2611,  1.6057],\n",
              "         ...,\n",
              "         [-1.4406,  0.3431,  1.4043,  ..., -0.0565,  0.8450, -0.2170],\n",
              "         [-1.3625, -0.2404,  1.1757,  ...,  0.8876, -0.1054,  0.0734],\n",
              "         [-1.4244,  0.1518,  1.2920,  ...,  0.0245,  0.7572,  0.0080]],\n",
              "\n",
              "        [[ 0.9371, -1.4749,  1.7351,  ..., -0.3426,  0.8050,  0.4031],\n",
              "         [ 1.6095, -1.7269,  2.7936,  ...,  0.3100, -0.4787, -1.2491],\n",
              "         [ 0.4861, -0.4569,  0.5712,  ..., -0.1769,  1.1253, -0.2756],\n",
              "         ...,\n",
              "         [ 1.2362, -0.6181,  2.0906,  ...,  1.3677,  0.8132, -0.2742],\n",
              "         [ 0.5409, -0.9652,  1.6237,  ...,  1.2395,  0.9185,  0.1782],\n",
              "         [ 1.9001, -0.5859,  3.0156,  ...,  1.4967,  0.1924, -0.4448]]],\n",
              "       grad_fn=<NativeLayerNormBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwDi0WNdrG7r"
      },
      "source": [
        "BERT 마지막 레이어의 문서 수준 벡터를 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FQ1nayZrLQl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a7c9487-b914-475f-864a-9907987350b0"
      },
      "source": [
        "outputs.pooler_output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1594,  0.0547,  0.1101,  ...,  0.2684,  0.1596, -0.9828],\n",
              "        [-0.9221,  0.2969, -0.0110,  ...,  0.4291,  0.0311, -0.9955]],\n",
              "       grad_fn=<TanhBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    }
  ]
}